{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding (word2vec) with Gensim. Train our own vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=2, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")\n",
    "#If you save the model you can continue training it later:\n",
    "#model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00515624, -0.00666834, -0.00777684,  0.00831073, -0.00198234,\n",
       "       -0.00685496, -0.00415439,  0.00514413, -0.00286914, -0.00374966,\n",
       "        0.00162143, -0.00277629, -0.00158436,  0.00107449, -0.00297795,\n",
       "        0.00851928,  0.00391094, -0.00995886,  0.0062596 , -0.00675426,\n",
       "        0.00076943,  0.00440423, -0.00510338, -0.00211067,  0.00809548,\n",
       "       -0.00424379, -0.00763626,  0.00925791, -0.0021555 , -0.00471943,\n",
       "        0.0085708 ,  0.00428334,  0.00432484,  0.00928451, -0.00845308,\n",
       "        0.00525532,  0.00203935,  0.00418828,  0.0016979 ,  0.00446413,\n",
       "        0.00448629,  0.00610452, -0.0032021 , -0.00457573, -0.00042652,\n",
       "        0.00253373, -0.00326317,  0.00605772,  0.00415413,  0.00776459,\n",
       "        0.00256927,  0.00811668, -0.00138721,  0.00807793,  0.00371701,\n",
       "       -0.00804733, -0.00393362, -0.00247188,  0.00489304, -0.00087216,\n",
       "       -0.00283091,  0.00783371,  0.0093229 , -0.00161493, -0.00515925,\n",
       "       -0.00470176, -0.00484605, -0.00960283,  0.00137202, -0.00422492,\n",
       "        0.00252671,  0.00561448, -0.00406591, -0.00959658,  0.0015467 ,\n",
       "       -0.00670012,  0.00249517, -0.00378063,  0.00707842,  0.00064022,\n",
       "        0.00356094, -0.00273913, -0.00171055,  0.00765279,  0.00140768,\n",
       "       -0.00585045, -0.0078345 ,  0.00123269,  0.00645463,  0.00555635,\n",
       "       -0.00897705,  0.00859216,  0.00404698,  0.0074696 ,  0.00974633,\n",
       "       -0.00728958, -0.00903996,  0.005836  ,  0.00939121,  0.00350693],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = model.wv.most_similar('minors', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trees', 0.17018744349479675),\n",
       " ('eps', 0.13888110220432281),\n",
       " ('time', 0.03476540371775627),\n",
       " ('graph', 0.0045036980882287025),\n",
       " ('human', -0.005896520800888538),\n",
       " ('system', -0.027751950547099113),\n",
       " ('response', -0.02849026769399643),\n",
       " ('user', -0.04462352395057678),\n",
       " ('survey', -0.06901613622903824),\n",
       " ('computer', -0.17323653399944305)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: What are the top ten words mentioned by Biden in the 105 congress (after stopwords removal)? For each most frequent word, find the 10 most simlar words generated using word2vec. Find the most frequent bigrams in the text. Explore some bigrams and figure out if the tokens appear in the list of most similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\n",
    "#https://github.com/zhlli1/Genism-word2vec/blob/master/Genism%20Word2Vec%20Tutorial.ipynb\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
